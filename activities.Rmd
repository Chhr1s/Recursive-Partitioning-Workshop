---
title: "activity"
author: "Christopher Loan"
date: "2022-12-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r}
imputed <- 
  rio::import(
    here::here('data', 'imputed_world_bank.csv')
  )
```

```{r}
sum(is.na(imputed))
```

```{r}
library(rsample)
set.seed(123)
split_data <- initial_split(imputed)

training_data_tmp <- 
  training(split_data) 

training_data_outcome <- 
  training_data_tmp %>% 
  select(outcome_next_year)

# these variables are too co-linear for same year prediction

training_sds <- 
  training_data_tmp %>% 
  select(
    -outcome_next_year, 
    -contains('tlf_cact'),
    -contains('sl_emp'),
    -contains('tlf_acti')
    ) %>% 
  mutate(
    across(
      .cols = everything(), 
      .fns = ~sd(.x, na.rm = T)
    )
  )
# even though these had variance, they don't in the training set
# we cannot learn from them

nzv_training <- 
  training_sds %>% 
  select(where(~sum(.x) == 0)) %>% 
  names()

training_sds <- 
  training_sds %>% 
  select(-any_of(nzv_training))

training_xs <- 
  training_data_tmp %>% 
  select(
    -any_of(nzv_training), 
    -outcome_next_year, 
    -contains('tlf_cact'),
    -contains('sl_emp'),
    -contains('tlf_acti')
    ) 

training_means <- 
  training_xs %>% 
  select(-any_of(nzv_training)) %>% 
  mutate(
    across(
      .cols = everything(), 
      .fns = ~mean(.x, na.rm = T)
    )
  )


training_tmp <- 
  (training_xs - training_means
    
    )/training_sds


training_data <- 
  training_data_outcome %>% 
  bind_cols(training_tmp)
```


```{r}
testing_data_tmp <- 
  testing(split_data) 

testing_data_outcome <- 
  testing_data_tmp %>% 
  select(outcome_next_year)

testing_xs <- 
  testing_data_tmp %>% 
  select(
    -outcome_next_year, 
    -any_of(nzv_training),
    -contains('tlf_cact'),
    -contains('sl_emp'),
    -contains('tlf_acti')
    )

testing_tmp <- 
  (testing_xs - training_means[1:nrow(testing_xs),]
    
    )/training_sds[1:nrow(testing_xs),]

testing_data <- 
  testing_data_outcome %>% 
  bind_cols(testing_tmp)
```

```{r}
library(rpart)
```

```{r}
dt_training <- 
  rpart(
    data = training_data, 
    formula = outcome_next_year ~ .
  )
```

```{r}
rpart.plot::rpart.plot(dt_training)
```

```{r}
dt_training
```

```{r}
library(pdp)
library(ranger)
```

```{r}
rf_training <- 
  ranger(
    data = training_data, 
    formula = outcome_next_year ~ .,
    importance = 'permutation'
  )
```

```{r}
library(vip)
vi <- vi(rf_training)
investigate_v <- vi$Variable[1:3]
vip(rf_training)
```


```{r}
library(pdp)
partial <- pdp::partial

partial(
  rf_training, 
  pred.var = investigate_v[1], 
  plot = T
)

partial(
  rf_training, 
  pred.var = investigate_v[2], 
  plot = T
)

partial(
  rf_training, 
  pred.var = investigate_v[3], 
  plot = T
)
```


```{r}
combos <- 
  data.frame(
    t(combn(investigate_v, 2))
    )
```


```{r}
f <- function(i) {
    partial(
      rf_training, 
      pred.var = unlist(combos[i,]),
      plot = F
    )
}
```


```{r}
library(parallel)
start_time <- Sys.time()
partial_list <- mclapply(1:3, f, mc.cores = 3)
stop_time <- Sys.time()
stop_time - start_time
```

```{r}
library(lattice)
plts_3d <- 
  map(
  .x = partial_list,
  .y = combos, 
  .f = ~{
    form <- 
      formula(
        paste(
          "yhat ~", 
          paste(
            names(.x)[1L:2L], 
            collapse = "*")
          )
      )
    wireframe(
      form, 
      data = .x, 
      drape =T, 
      scale = list(arrows = F)
    )
  }
)

plts_3d
```

```{r}
mae <- function(observed_y, predicted_y) 
  {mean(abs(observed_y - predicted_y))/length(observed_y)}
```


```{r}
actual_vs_pred <- 
  testing_data %>% 
  mutate(
    # in this context, the . means "what's carried from the pipe"
    predicted_DT = 
      predict(dt_training, newdata = testing_data), 
    predicted_RF = 
      predict(rf_training, data = testing_data)$predictions
  ) %>% 
  pivot_longer(
    cols = starts_with('predicted'), 
    names_to = 'model',
    values_to = 'prediction',
    names_prefix = 'predicted_'
  ) %>% 
  select(
    outcome_next_year,
    model, 
    prediction, 
    year
  )
```


```{r}
actual_vs_pred %>% 
  mutate(
    year = (year * training_sds$year[1]) + training_means$year[1]
  ) %>% 
  ggplot(
    aes(
      x = prediction,
      y = outcome_next_year,
      color = model, 
      fill = model
    )
  ) + 
  geom_abline(
    intercept = 0, 
    slope = 1, 
    linetype = 2,
    size = 2,
    color = 'gray70'
  ) +
  geom_point(
    shape = 21, 
    color = 'black',
    size = 5,
    alpha = 0.5
  ) +
  ggrepel::geom_label_repel(
    aes(label = year), 
    color = 'black', 
    max.overlaps = 14,
    min.segment.length = 0.01
  ) +
  labs(
    y = 'True Workforce (%)\n(Next Year)',
    x = 'Predited Workforce (%)\n(Next Year)',
    
  ) +
  theme_bw()
```


```{r}
fit_to_data <- 
  actual_vs_pred %>% 
  group_by(model) %>% 
  summarize(
    MAE = mae(
      observed_y = outcome_next_year, 
      predicted_y = prediction
    ), 
    RMSE = rmse(
      observed_y = outcome_next_year, 
      predicted_y = prediction
    )
  )

fit_to_data
```

```{r}
cv_obj <- vfold_cv(training_data, v = 5)
```

```{r}
library(dials)
```

```{r}
max_entropy_grid <- 
  grid_max_entropy(
    # default = floor(sqrt(ncol(training_data))) = 24
    mtry(range = c(18, 100)),
    trees(range = c(400, 1000)), 
    size = 10
  )

tuned_res <- 
  cv_it(
    cv_obj = cv_obj, 
    outcome_string = 'outcome_next_year',
    seed = 333,
    mod_formula = outcome_next_year ~ .,
    tuning_grid = max_entropy_grid
  ) 
```

```{r}
tuned_res
```



```{r}
pos_d <- 
  position_dodge(width = 1)



plot_df <- 
  tuned_res %>% 
  pivot_longer(
    cols = c(mean_rmse:se_mae),
    names_to = c('.value', 'metric'),
    names_sep = '_'
  ) 

plot_df %>% 
  ggplot(
    aes(
      y = factor(grid_index), 
      x = mean, 
      fill = metric,
      group = metric, 
      xmin = mean - 1.96*se, 
      xmax = mean + 1.96*se
    )
  ) + 
  geom_col(color = 'black') + 
  geom_errorbar(width = 0.2, color = 'black') + 
  geom_label(
    aes(label = round(mean, 3)),
    color = 'black'
  ) +
  theme_bw() + 
  labs(
    caption = 
      '95% CIs drawn with t-distribution\nuse to conceptualize spread, not assess significance'
  ) +
  theme(
    plot.caption.position = 'plot',
    plot.title.position = 'plot'
    ) +
  facet_wrap(vars(metric), scales = 'free') + 
  labs(
    y = 'Grid index',
    x = 'Average Fit'
    )
```

```{r}
final_mtry <- 
  tuned_res %>% 
  filter(mean_rmse == min(mean_rmse)) %>% 
  pull(mtry)

final_trees <- 
  tuned_res %>% 
  filter(mean_rmse == min(mean_rmse)) %>% 
  pull(trees)
```

```{r}
rf_tuned <- 
  ranger(
    data = training_data, 
    formula = outcome_next_year ~ .,
    importance = 'permutation',
    mtry = final_mtry,
    num.trees = final_trees
  )
```

```{r}
actual_vs_pred <- 
  testing_data %>% 
  mutate(
    # in this context, the . means "what's carried from the pipe"
    predicted_DT = 
      predict(dt_training, newdata = testing_data), 
    predicted_RF = 
      predict(rf_training, data = testing_data)$predictions,
    predicted_RF.tuned = 
      predict(rf_tuned, data = testing_data)$predictions,
  ) %>% 
  pivot_longer(
    cols = starts_with('predicted'), 
    names_to = 'model',
    values_to = 'prediction',
    names_prefix = 'predicted_'
  ) %>% 
  select(
    outcome_next_year,
    model, 
    prediction, 
    year
  )

```

```{r}
actual_vs_pred %>% 
  mutate(
    year = (year * training_sds$year[1]) + training_means$year[1]
  ) %>% 
  ggplot(
    aes(
      x = prediction,
      y = outcome_next_year,
      color = model, 
      fill = model
    )
  ) + 
  geom_abline(
    intercept = 0, 
    slope = 1, 
    linetype = 2,
    size = 2,
    color = 'gray70'
  ) +
  geom_point(
    shape = 21, 
    color = 'black',
    size = 5,
    alpha = 0.5
  ) +
  ggrepel::geom_label_repel(
    aes(label = year), 
    color = 'black', 
    max.overlaps = 14,
    min.segment.length = 0.01
  ) +
  labs(
    y = 'True Workforce (%)\n(Next Year)',
    x = 'Predited Workforce (%)\n(Next Year)',
    
  ) +
  theme_bw()
```

```{r}
actual_vs_pred %>% 
  mutate(
    year = (year * training_sds$year[1]) + training_means$year[1]
  ) %>% 
  group_by(model) %>% 
  group_by(model) %>% 
  summarize(
    MAE = mae(
      observed_y = outcome_next_year, 
      predicted_y = prediction
    ), 
    RMSE = rmse(
      observed_y = outcome_next_year, 
      predicted_y = prediction
    )
  )
```

