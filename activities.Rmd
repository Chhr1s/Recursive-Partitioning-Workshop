---
title: "activity"
author: "Christopher Loan"
date: "2022-12-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# data sources
# https://data.worldbank.org/topic/education?locations=TH
```

```{r}
set.seed(4444)
library(tidyverse)
library(janitor)
source(here::here('functions.R'))
dat <- 
  rio::import(
    here::here(
      'data/thai_education',
      'world_bank_thai_education.csv'
    ),
    skip = 4,
  ) %>% 
  tibble() %>% 
  row_to_names(row_number = 1) %>% 
  clean_names() %>% 
  select(
    country_name, 
    indicator_name, 
    indicator_code, 
    x1990:x2018
  )

# make a key so we have all variables easily searchable
key <- 
  dat %>% 
  select(
    indicator_name, 
    indicator_code
    ) %>% 
  mutate(
    janitor_version = janitor::make_clean_names(indicator_code)
  )
```

```{r}
library(sjmisc)
cleaned <- 
  dat %>% 
  mutate(
    janitor_version = janitor::make_clean_names(indicator_code)
  ) %>% 
  select(-indicator_name, -indicator_code, -country_name) %>% 
  relocate(janitor_version, .before = everything()) %>% 
  rotate_df() %>% 
  row_to_names(row_number = 1) %>% 
  rownames_to_column(var = 'year') %>% 
  tibble() %>% 
  mutate(
    year = str_extract(string = year, regex('\\d\\d\\d\\d')),
    across(.cols = everything(), as.numeric)
  )
```

`sl_tlf_cact_zs` = Labor force participation rate, total (% of total population ages 15+) (modeled ILO estimate)

`sl_uem_neet_zs` = Share of youth not in education, employment or training, total (% of youth population)

`se_sec_durs` = Secondary education, duration (years)

```{r}
key
```

```{r}
nzv_vars <- 
  names(which(apply(cleaned, 2, var) < 0.1))

df_to_impute <- 
  cleaned %>% 
  # only retain rows with < 10% missingness
  select(
    where(~sum(is.na(.x)) < 0.1*nrow(cleaned)) &
      -all_of(nzv_vars)
  )

# select an outcome with no missingness

full_variables <- 
  df_to_impute %>% 
  # only retain rows with < 10% missingness
  select(where(~sum(is.na(.x))==0)) %>% 
  names()


outcome_key <- 
  key %>% 
  filter(
     janitor_version %in% full_variables & 
       !janitor_version %in% nzv_vars
  )


# https://ilostat.ilo.org/resources/concepts-and-definitions/ilo-modelled-estimates/


outcome_descriptor <-
  outcome_key %>% 
  filter(janitor_version == 'sl_tlf_cact_zs') %>% 
  pull(indicator_name)

# more information at:
# https://ilostat.ilo.org/resources/concepts-and-definitions/ilo-modelled-estimates/

```


we're going to use median impute

```{r eval=FALSE, include=FALSE}
plt <-
  cleaned %>% 
  pivot_longer(
    cols = -year
  ) %>% 
  ggplot(
    aes(
      x = value, 
      color = name, 
      fill = name
    )
  ) + 
  geom_density(
    show.legend = FALSE
  ) 

plt +
  lims(x = c(0, 25))
``` 

```{r}
# differences between mean and median aren't that great (in most cases)
cleaned %>% 
  summarize(
    across(.cols = everything(),.fns = ~median(.x) - mean(.x))
  ) 
```


```{r}
sum(is.na(cleaned$sl_tlf_cact_zs))

imputed <- 
  df_to_impute %>% 
  arrange(year) %>% 
  mutate(
    outcome_next_year = lead(sl_tlf_cact_zs, order_by = year)
    ) %>% 
  drop_na(outcome_next_year) %>% 
  mutate(
    across(
      # no missigness in the outcome
      .cols = everything(), 
      .fns = 
         ~ifelse(
           is.na(.x),
           median(.x, na.rm = T),
           .x)
    )
  )

```

```{r}
sum(is.na(imputed))
```

```{r}
library(rsample)
set.seed(123)
split_data <- initial_split(imputed)

training_data_tmp <- 
  training(split_data) 

training_data_outcome <- 
  training_data_tmp %>% 
  select(outcome_next_year)


training_sds <- 
  training_data_tmp %>% 
  select(
    -outcome_next_year, 
    -contains('tlf_cact'),
    -contains('sl_emp'),
    -contains('tlf_acti')
    ) %>% 
  mutate(
    across(
      .cols = everything(), 
      .fns = ~sd(.x, na.rm = T)
    )
  )
# even though these had variance, they don't in the training set
# we cannot learn from them

nzv_training <- 
  training_sds %>% 
  select(where(~sum(.x) == 0)) %>% 
  names()

training_sds <- 
  training_sds %>% 
  select(-any_of(nzv_training))

training_xs <- 
  training_data_tmp %>% 
  select(
    -any_of(nzv_training), 
    -outcome_next_year, 
    -contains('tlf_cact'),
    -contains('sl_emp'),
    -contains('tlf_acti')
    ) 

training_means <- 
  training_xs %>% 
  select(-any_of(nzv_training)) %>% 
  mutate(
    across(
      .cols = everything(), 
      .fns = ~mean(.x, na.rm = T)
    )
  )


training_tmp <- 
  (training_xs - training_means
    
    )/training_sds


training_data <- 
  training_data_outcome %>% 
  bind_cols(training_tmp)
```


```{r}
testing_data_tmp <- 
  testing(split_data) 

testing_data_outcome <- 
  testing_data_tmp %>% 
  select(outcome_next_year)

testing_xs <- 
  testing_data_tmp %>% 
  select(
    -outcome_next_year, 
    -any_of(nzv_training),
    -contains('tlf_cact'),
    -contains('sl_emp'),
    -contains('tlf_acti')
    )

testing_tmp <- 
  (testing_xs - training_means[1:nrow(testing_xs),]
    
    )/training_sds[1:nrow(testing_xs),]

testing_data <- 
  testing_data_outcome %>% 
  bind_cols(testing_tmp)
```

```{r}
library(rpart)
```

```{r}
dt_training <- 
  rpart(
    data = training_data, 
    formula = outcome_next_year ~ .
  )
```

```{r}
rpart.plot::rpart.plot(dt_training)
```

```{r}
dt_training
```

```{r}
library(pdp)
library(ranger)
```

```{r}
rf_training <- 
  ranger(
    data = training_data, 
    formula = outcome_next_year ~ .,
    importance = 'permutation'
  )
```

```{r}
library(vip)
vi <- vi(rf_training)
investigate_v <- vi$Variable[1:3]
vip(rf_training)
```


```{r}
library(pdp)
partial <- pdp::partial

partial(
  rf_training, 
  pred.var = investigate_v[1], 
  plot = T
)

partial(
  rf_training, 
  pred.var = investigate_v[2], 
  plot = T
)

partial(
  rf_training, 
  pred.var = investigate_v[3], 
  plot = T
)
```


```{r}
combos <- 
  data.frame(
    t(combn(investigate_v, 2))
    )
```


```{r}
f <- function(i) {
    partial(
      rf_training, 
      pred.var = unlist(combos[i,]),
      plot = F
    )
}
```


```{r}
library(parallel)
start_time <- Sys.time()
partial_list <- mclapply(1:3, f, mc.cores = 3)
stop_time <- Sys.time()
stop_time - start_time
```

```{r}
library(lattice)
plts_3d <- 
  map(
  .x = partial_list,
  .y = combos, 
  .f = ~{
    form <- 
      formula(
        paste(
          "yhat ~", 
          paste(
            names(.x)[1L:2L], 
            collapse = "*")
          )
      )
    wireframe(
      form, 
      data = .x, 
      drape =T, 
      scale = list(arrows = F)
    )
  }
)

plts_3d
```

```{r}
mae <- function(observed_y, predicted_y) 
  {mean(abs(observed_y - predicted_y))/length(observed_y)}
```


```{r}
actual_vs_pred <- 
  testing_data %>% 
  mutate(
    # in this context, the . means "what's carried from the pipe"
    predicted_DT = 
      predict(dt_training, newdata = testing_data), 
    predicted_RF = 
      predict(rf_training, data = testing_data)$predictions
  ) %>% 
  pivot_longer(
    cols = starts_with('predicted'), 
    names_to = 'model',
    values_to = 'prediction',
    names_prefix = 'predicted_'
  ) %>% 
  select(
    outcome_next_year,
    model, 
    prediction, 
    year
  )
```


```{r}
actual_vs_pred %>% 
  mutate(
    year = (year * training_sds$year[1]) + training_means$year[1]
  ) %>% 
  ggplot(
    aes(
      x = prediction,
      y = outcome_next_year,
      color = model, 
      fill = model
    )
  ) + 
  geom_abline(
    intercept = 0, 
    slope = 1, 
    linetype = 2,
    size = 2,
    color = 'gray70'
  ) +
  geom_point(
    shape = 21, 
    color = 'black',
    size = 5,
    alpha = 0.5
  ) +
  ggrepel::geom_label_repel(
    aes(label = year), 
    color = 'black', 
    max.overlaps = 14,
    min.segment.length = 0.01
  ) +
  labs(
    y = 'True Workforce (%)\n(Next Year)',
    x = 'Predited Workforce (%)\n(Next Year)',
    
  ) +
  theme_bw()
```


```{r}
fit_to_data <- 
  actual_vs_pred %>% 
  group_by(model) %>% 
  summarize(
    MAE = mae(
      observed_y = outcome_next_year, 
      predicted_y = prediction
    ), 
    RMSE = rmse(
      observed_y = outcome_next_year, 
      predicted_y = prediction
    )
  )

fit_to_data
```

```{r}
cv_obj <- vfold_cv(training_data, v = 5)
```

```{r}
library(dials)
```

```{r}
max_entropy_grid <- 
  grid_max_entropy(
    # default = floor(sqrt(ncol(training_data))) = 24
    mtry(range = c(18, 100)),
    trees(range = c(400, 1000)), 
    size = 10
  )

tuned_res <- 
  cv_it(
    cv_obj = cv_obj, 
    outcome_string = 'outcome_next_year',
    seed = 333,
    mod_formula = outcome_next_year ~ .,
    tuning_grid = max_entropy_grid
  ) 
```


```{r}
pos_d <- 
  position_dodge(width = 1)



plot_df <- 
  tuned_res %>% 
  pivot_longer(
    cols = c(mean_rmse:se_mae),
    names_to = c('.value', 'metric'),
    names_sep = '_'
  ) 

plot_df %>% 
  ggplot(
    aes(
      x = grid_index, 
      y = mean, 
      fill = metric,
      color = metric,
      group = metric, 
      ymin = mean - 1.96*se, 
      ymax = mean + 1.96*se,
    )
  ) +
  scale_x_continuous(
    breaks = 1:10
  ) +
  geom_errorbar(position = pos_d) + 
  geom_point(position = pos_d) + 
  geom_label(
    aes(
      label = round(mean, 3)
    ),
      color = 'black',
    position = pos_d,
  ) +
  theme_bw() + 
  coord_flip() +
  labs(
    caption = 
      'CIs drawn with t-distribution; use to conceptualize spread, not assess significance'
  ) +
  theme(
    plot.caption.position = 'plot',
    plot.title.position = 'plot'
    )
```

```{r}
final_mtry <- 
  tuned_res %>% 
  filter(mean_rmse == min(mean_rmse)) %>% 
  pull(mtry)

final_trees <- 
  tuned_res %>% 
  filter(mean_rmse == min(mean_rmse)) %>% 
  pull(trees)
```

```{r}
rf_tuned <- 
  ranger(
    data = training_data, 
    formula = outcome_next_year ~ .,
    importance = 'permutation',
    mtry = final_mtry,
    num.trees = final_trees
  )
```

```{r}

actual_vs_pred <- 
  testing_data %>% 
  mutate(
    # in this context, the . means "what's carried from the pipe"
    predicted_DT = 
      predict(dt_training, newdata = testing_data), 
    predicted_RF = 
      predict(rf_training, data = testing_data)$predictions,
    predicted_RF.tuned = 
      predict(rf_tuned, data = testing_data)$predictions,
  ) %>% 
  pivot_longer(
    cols = starts_with('predicted'), 
    names_to = 'model',
    values_to = 'prediction',
    names_prefix = 'predicted_'
  ) %>% 
  select(
    outcome_next_year,
    model, 
    prediction, 
    year
  )

```

```{r}
actual_vs_pred %>% 
  mutate(
    year = (year * training_sds$year[1]) + training_means$year[1]
  ) %>% 
  ggplot(
    aes(
      x = prediction,
      y = outcome_next_year,
      color = model, 
      fill = model
    )
  ) + 
  geom_abline(
    intercept = 0, 
    slope = 1, 
    linetype = 2,
    size = 2,
    color = 'gray70'
  ) +
  geom_point(
    shape = 21, 
    color = 'black',
    size = 5,
    alpha = 0.5
  ) +
  ggrepel::geom_label_repel(
    aes(label = year), 
    color = 'black', 
    max.overlaps = 14,
    min.segment.length = 0.01
  ) +
  labs(
    y = 'True Workforce (%)\n(Next Year)',
    x = 'Predited Workforce (%)\n(Next Year)',
    
  ) +
  theme_bw()
```

```{r}
actual_vs_pred %>% 
  mutate(
    year = (year * training_sds$year[1]) + training_means$year[1]
  ) %>% 
  group_by(model) %>% 
  group_by(model) %>% 
  summarize(
    MAE = mae(
      observed_y = outcome_next_year, 
      predicted_y = prediction
    ), 
    RMSE = rmse(
      observed_y = outcome_next_year, 
      predicted_y = prediction
    )
  )
```

