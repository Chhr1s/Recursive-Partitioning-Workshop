---
title: "aggregated_cleaning"
author: "Christopher Loan"
date: "2023-01-01"
output: html_document
---

```{r}
# data sources
# https://data.worldbank.org/topic/
```

```{r}
outcome_next_year <- 'se_prm_enrr'
library(tidyverse)
library(janitor)
library(sjmisc)
library(parallel)
source(here::here('scripts/functions.R'))
```


```{r}
raw_files <- 
  list.files(here::here('data/raw_data'))

names(raw_files) <- 
  gsub('.csv', '', 
       gsub('wb_all_countries_', '', raw_files)
       )

se_asia <- 
  c(
    'Brunei Darussalam', 
    'Myanmar', 
    'Cambodia', 
    'Timor-Leste', 
    'Indonesia', 
    'Lao PDR', 
    'Malaysia', 
    'Philippines', 
    'Singapore', 
    'Thailand',
    'Vietnam'
  )

dat <- 
  map_dfr(
    .x = raw_files, 
    .f = 
      ~rio::import(
        here::here(
          'data/raw_data', .x
        ),
        skip = 4,
      ) %>% 
      tibble() %>% 
      row_to_names(row_number = 1) %>% 
      clean_names() %>%
      select(
        country_name, 
        indicator_name, 
        indicator_code, 
        starts_with('x')
      ),
    .id = 'import_file_source'
  ) %>% 
  filter(country_name %in% se_asia)


```



```{r}
# make a key so we have all variables easily searchable
key <- 
  dat %>% 
  select(
    indicator_name, 
    indicator_code
    ) %>% 
  mutate(
    janitor_version = janitor::make_clean_names(indicator_code)
  )
```

```{r}
cleaned <- 
  dat %>% 
  group_by(country_name) %>% 
  nest() %>% 
  mutate(
    data = 
      map(
        .x = data, 
        .f =
        ~{.x %>% 
            mutate(janitor_version = janitor::make_clean_names(indicator_code)) %>% 
            select(-indicator_name, -indicator_code, -import_file_source) %>% 
            relocate(janitor_version, .before = everything()) %>% 
            rotate_df() %>%
            row_to_names(row_number = 1) %>%
            rownames_to_column(var = 'year') %>%
            tibble() %>%
            mutate(
              year = str_extract(string = year, regex('\\d\\d\\d\\d')),
              across(.cols = everything(), ~as.numeric(.x))
            )
        }
      ) 
  ) %>% 
  unnest(data) %>% 
  ungroup()
```

`sl_tlf_cact_zs` = Labor force participation rate, total (% of total population ages 15+) (modeled ILO estimate)

`sl_uem_neet_zs` = Share of youth not in education, employment or training, total (% of youth population)

`se_sec_durs` = Secondary education, duration (years)

```{r}
key
```

```{r}
missingness_counter <-
  cleaned %>%
  group_by(country_name) %>%
  nest() %>%
  mutate(
    data =
      mclapply(
        mc.cores = 9L,
        X = data,
        FUN = function(x) {sum(is.na(x))}
      )
  ) %>%
  unnest(data) %>%
  ungroup()

missingness_counter %>% 
  arrange(desc(data)) 


sum(is.na(cleaned)) / (ncol(cleaned) * nrow(cleaned))
```

```{r}
library(janitor)
clean_subset <- 
  cleaned %>% 
  filter(
    year >= 2000
    ) %>% 
  remove_constant() %>% 
  remove_empty(which = 'cols') %>% 
  remove_empty(which = 'rows') 
```

```{r}
variables_to_include <- 
  key %>% 
  mutate(
    base_info = sub("\\s*\\(.*", "", indicator_name)
  ) %>% 
  distinct(base_info, .keep_all = TRUE) %>% 
  pull(janitor_version) 


near_zero_variance <-
  names(which(apply(select(clean_subset, -country_name), 2, var, na.rm = TRUE) < 0.2))

df_to_impute <-
  clean_subset %>% 
  select(
    where(
      ~sum(is.na(.x))/nrow(clean_subset) < 0.25 
      ) & -all_of(near_zero_variance)
  ) 

# removing variables which are in different units but are otherwise equivalent

eligible_vars <- 
  df_to_impute %>% 
  names() 

impute_key <- 
  key %>% 
  filter(
    janitor_version %in% variables_to_include & 
      janitor_version %in% eligible_vars
  ) 


  
# only 9 % missing is good balance of lots of variables 
sum(is.na(df_to_impute))/(nrow(df_to_impute)*ncol(df_to_impute))
# select an outcome with no missingness

full_variables <- 
  df_to_impute %>% 
  # only retain rows with < 5% missingness:
  select(where(~sum(is.na(.x)) < 0.05*nrow(df_to_impute))) %>% 
  # no missingness:
  #select(where(~sum(is.na(.x))==0)) %>% 
  names()


outcome_key <- 
  key %>% 
  filter(
     janitor_version %in% full_variables #& 
       #!janitor_version %in% near_zero_variance
  )


outcome_descriptor <-
  outcome_key %>% 
  filter(janitor_version == outcome_next_year) %>% 
  pull(indicator_name)

# more information at:
# https://ilostat.ilo.org/resources/concepts-and-definitions/ilo-modelled-estimates/

```


```{r}
# because we're in the world of random forests
# i'm going to use `missRanger` to impute the data. this works 
library(missRanger)
set.seed(123)
imputed <- 
  df_to_impute %>% 
  missRanger(pmm.k = 3, seed = 123)
  

output_data <- 
  imputed %>% 
  group_by(country_name) %>% 
  nest() %>% 
  mutate(
    data = 
      map(
        .x = data, 
        .f = 
          ~.x %>% 
          arrange(year) %>% 
          mutate(
            ## check this
            outcome_next_year = lead(!!sym(outcome_next_year), order_by = year)
          ) %>% 
        # removes any potential issue from the `lead()` call
        # also removes prediction into covid years
          drop_na(outcome_next_year) 
  )
  ) %>% 
  unnest(data) %>% 
  ungroup() %>% 
  # this keeps out covid issues and also 
  filter(year <= 2018) 

# output_data %>% 
#   select(outcome_next_year, !!sym(outcome_next_year), year, country_name)
```

```{r}
rio::export(output_data, here::here('data', 'se_asia_imputed_world_bank.csv'))
rio::export(key, here::here('data', 'keys/key_full.csv'))
rio::export(impute_key, here::here('data', 'keys/key_impute.csv'))
rio::export(outcome_key, here::here('data', 'keys/key_outcomes_only.csv'))
```

