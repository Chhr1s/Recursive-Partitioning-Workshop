---
title: "aggregated_cleaning"
author: "Christopher Loan"
date: "2023-01-01"
output: html_document
---

```{r}
# data sources
# https://data.worldbank.org/topic/
```

```{r}
set.seed(022023)
outcome_next_year <- 'se_xpd_totl_gd_zs'
library(tidyverse)
library(janitor)
library(sjmisc)
library(parallel)
source(here::here('scripts/functions.R'))
```


```{r}
raw_files <- 
  list.files(here::here('data/raw_data'))

names(raw_files) <- 
  gsub('.csv', '', 
       gsub('wb_all_countries_', '', raw_files)
       )

se_asia <- 
  c(
# removed countries have too observations of 
# outcome to have unbiased imputation
    #'Brunei Darussalam', 
    #'Myanmar', 
    'Cambodia', 
    #'Timor-Leste', 
    'Indonesia', 
    'Lao PDR', 
    'Malaysia', 
    'Philippines', 
    'Singapore', 
    'Thailand',
    'Vietnam'
  )

dat <- 
  map_dfr(
    .x = raw_files, 
    .f = 
      ~rio::import(
        here::here(
          'data/raw_data', .x
        ),
        skip = 4,
      ) %>% 
      tibble() %>% 
      row_to_names(row_number = 1) %>% 
      clean_names() %>%
      select(
        country_name, 
        indicator_name, 
        indicator_code, 
        starts_with('x')
      ),
    .id = 'import_file_source'
  ) %>% 
  filter(country_name %in% se_asia) %>% 
  distinct(
    indicator_code, country_name, .keep_all = TRUE
  )
```

```{r}
cleaned <- 
  dat %>% 
  group_by(country_name) %>% 
  nest() %>% 
  mutate(
    data = 
      map(
        .x = data, 
        .f =
        ~{.x %>% 
            mutate(janitor_version = make_clean_names(indicator_code)) %>% 
            select(-indicator_name, -indicator_code, -import_file_source) %>% 
            relocate(janitor_version, .before = everything()) %>% 
            rotate_df() %>%
            row_to_names(row_number = 1) %>%
            rownames_to_column(var = 'year') %>%
            tibble() %>%
            mutate(
              year = str_extract(string = year, regex('\\d\\d\\d\\d')),
              across(.cols = everything(), ~as.numeric(.x))
            )
        }
      ) 
  ) %>% 
  unnest(data) %>% 
  ungroup()
```


```{r}
# make a key so we have all variables easily searchable
key <- 
  dat %>% 
  distinct(
    indicator_name, 
    indicator_code,
    import_file_source
    ) %>% 
  mutate(
    janitor_version = make_clean_names(indicator_code)
  ) %>% 
  relocate(janitor_version, indicator_name, indicator_code, import_file_source) 
```


```{r}
missingness_counter <-
  cleaned %>%
  group_by(country_name) %>%
  nest() %>%
  mutate(
    data =
      mclapply(
        mc.cores = 9L,
        X = data,
        FUN = function(x) {sum(is.na(x))}
      )
  ) %>%
  unnest(data) %>%
  ungroup()

missingness_counter %>% 
  arrange(desc(data)) 

# that's a lot
sum(is.na(cleaned)) / (ncol(cleaned) * nrow(cleaned))
```

```{r}
clean_subset <- 
  cleaned %>% 
  filter(
    year >= 2000
    ) %>% 
  remove_constant() %>% 
  remove_empty(which = 'cols') %>% 
  remove_empty(which = 'rows') 
```

```{r}
selecting_from_suffixes <-
  key %>%
  mutate(
    #janitor_version2 = janitor_version,
    topic_2 = substr(janitor_version, 1, 2),
    general_subject_3 = substr(janitor_version, 4, 6),
    specific_subject_4 = substr(janitor_version, 8, 11),
    extension_a_2 = substr(janitor_version, 13, 14),
    extension_b_2 = substr(janitor_version, 16, 17),
    extension_c_2 = substr(janitor_version, 19, 20),
    across(
      .cols = c(
        topic_2, 
        general_subject_3, 
        specific_subject_4,
        extension_a_2, 
        extension_b_2, 
        extension_c_2
        ),
      .fns = ~.x %>% na_if('')
      )
    )

# definitely want these:

# those which do not have subcategories

variables_to_include_a <- 
  selecting_from_suffixes %>% 
  filter(
    is.na(extension_a_2) & is.na(extension_b_2) & is.na(extension_c_2)
  ) %>% 
  pull(janitor_version)

tmp_string <- paste0('^', variables_to_include_a)
names(tmp_string) <- variables_to_include_a

# these are ones with subcategories AND main reporting. 
# we just want the main reporting b/c subcategories are colinear
variables_to_include_b <- 
  tmp_string %>% 
  map_dfr(
    .f = 
      ~selecting_from_suffixes %>% 
        filter(grepl(.x, janitor_version)),
    .id = 'base_variable'
  ) %>% 
  filter(is.na(extension_a_2)) %>% 
  pull(janitor_version)


## this clear up some redundant information

variables_to_include_c <- 
  selecting_from_suffixes %>% 
  filter(specific_subject_4 == 'totl') %>% 
  group_by(topic_2, general_subject_3, specific_subject_4) %>% 
  slice(1) %>% 
  ungroup() %>% 
  pull(janitor_version)


```
  

```{r}
# variables_to_include <- 
#   key %>% 
#   mutate(
#     base_info = sub("\\s*\\(.*", "", indicator_name)
#   ) %>% 
#   distinct(base_info, .keep_all = TRUE) %>% 
#   pull(janitor_version) 


variables_to_include <- 
  c(variables_to_include_a,
    variables_to_include_b,
    variables_to_include_c
    )

near_zero_variance <-
  names(which(apply(select(clean_subset, -country_name), 2, var, na.rm = TRUE) < 0.1))

df_to_impute <-
  clean_subset %>% 
  select(
    country_name, 
    year,
    # all possible variables
    all_of(variables_to_include)
    ) %>% 
  select(
  # those without more than 25% missingness
    where(
      ~sum(is.na(.x))/nrow(clean_subset) < 0.25 
      )
  ) 

# removing variables which are in different units but are otherwise equivalent

eligible_vars <- 
  df_to_impute %>% 
  names() 

impute_key <- 
  key %>% 
  filter(
    janitor_version %in% variables_to_include & 
      janitor_version %in% eligible_vars
  ) 

# missingness to number of variable balance is good
sum(is.na(df_to_impute))/(nrow(df_to_impute)*ncol(df_to_impute))
# select an outcome with no missingness

mostly_full <- 
  df_to_impute %>%
  # only retain rows with < 15% missingness:
  select(where(~sum(is.na(.x)) < 0.15*nrow(df_to_impute))) %>% 
  names()


outcome_key <- 
  key %>% 
  filter(
     janitor_version %in% mostly_full & 
       !janitor_version %in% near_zero_variance
  )

outcome_descriptor <-
  outcome_key %>% 
  filter(janitor_version == outcome_next_year) %>% 
  pull(indicator_name)


```


```{r}
# because we're in the world of random forests
# `missRanger` to impute the data
library(missRanger)
imputed <- 
  df_to_impute %>% 
  missRanger(pmm.k = 3, seed = 022023)
  

output_data <- 
  imputed %>% 
  group_by(country_name) %>% 
  nest() %>% 
  mutate(
    data = 
      map(
        .x = data, 
        .f = 
          ~.x %>% 
          arrange(year) %>% 
          mutate(
            ## check this
            outcome_next_year = lead(!!sym(outcome_next_year), order_by = year)
          ) %>% 
        # removes any potential issue from the `lead()` call
        # also removes prediction into covid years
          drop_na(outcome_next_year) 
  )
  ) %>% 
  unnest(data) %>% 
  ungroup() %>% 
  # this keeps out covid issues and also 
  filter(year <= 2018)
```

```{r}
output_data %>%
  select(outcome_next_year, !!sym(outcome_next_year), year, country_name)
```

```{r eval=FALSE, include=FALSE}
cleaned %>% 
  relocate(se_xpd_totl_gd_zs, .before = everything()) %>% 
  select(
    country_name, 
    year,
    any_of(
      
        key %>% 
        filter(
          import_file_source == 'education'
          ) %>% 
          pull(janitor_version)
        
      )
    ) %>% 
  summarize(across(.fns = ~sum(is.na(.x)))) %>% t()
```


```{r}
rio::export(output_data, here::here('data', 'se_asia_imputed_world_bank.csv'))
rio::export(key, here::here('data', 'keys/key_full.csv'))
rio::export(impute_key, here::here('data', 'keys/key_impute.csv'))
rio::export(outcome_key, here::here('data', 'keys/key_outcomes_only.csv'))
```

