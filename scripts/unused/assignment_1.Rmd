---
title: "Assignment 1"
author: "Christopher Loan"
date: "2022-12-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Libraries

```{r}
library(tidyverse)
library(rpart)
```

```{r}
set.seed(4444)
library(janitor)
source(here::here('functions.R'))
dat <- 
  rio::import(
    here::here(
      'data/thai_education',
      'world_bank_thai_education.csv'
    ),
    skip = 4,
  ) %>% 
  tibble() %>% 
  row_to_names(row_number = 1) %>% 
  clean_names() %>%
  select(
    country_name, 
    indicator_name, 
    indicator_code, 
    starts_with('x')
  )

# make a key so we have all variables easily searchable
key <- 
  dat %>% 
  select(
    indicator_name, 
    indicator_code
    ) %>% 
  mutate(
    janitor_version = janitor::make_clean_names(indicator_code)
  )
```

```{r}
library(sjmisc)
cleaned <- 
  dat %>% 
  mutate(
    janitor_version = janitor::make_clean_names(indicator_code)
  ) %>% 
  select(-indicator_name, -indicator_code, -country_name) %>% 
  relocate(janitor_version, .before = everything()) %>% 
  rotate_df() %>% 
  row_to_names(row_number = 1) %>% 
  rownames_to_column(var = 'year') %>% 
  tibble() %>% 
  mutate(
    year = str_extract(string = year, regex('\\d\\d\\d\\d')),
    across(.cols = everything(), as.numeric)
  )
```

```{r}

```


```{r}
zv_vars <- 
  names(which(apply(cleaned, 2, var) < 0.1))

df_to_impute <- 
  cleaned %>% 
  # only retain rows with < 10% missingness
  select(
    where(~sum(is.na(.x)) < 0.1*nrow(cleaned)) &
      -all_of(zv_vars)
  ) %>% 
  mutate(
    le_next_year = lead(sp_dyn_le00_in, order_by = year)
      
  ) %>% 
  #select(le_next_year, sp_dyn_le00_in, year) %>% 
  filter(year != min(year)) %>% 
  drop_na(le_next_year)

# select an outcome with no missingness

full_variables <- 
  df_to_impute %>% 
  # only retain rows with < 10% missingness
  select(where(~sum(is.na(.x))==0)) %>% 
  names()


outcome_key <- 
  key %>% 
  filter(
     janitor_version %in% full_variables & 
       !janitor_version %in% zv_vars
  )


# https://ilostat.ilo.org/resources/concepts-and-definitions/ilo-modelled-estimates/


outcome_descriptor <-
  outcome_key %>% 
  filter(janitor_version == 'sp_dyn_le00_in') %>% 
  pull(indicator_name)

# more information at:
# https://ilostat.ilo.org/resources/concepts-and-definitions/ilo-modelled-estimates/

```


we're going to use median impute

```{r}
# differences between mean and median aren't that great (in most cases)
cleaned %>% 
  summarize(
    across(.cols = everything(),.fns = ~median(.x, na.rm = T) - mean(.x, na.rm = T))
  ) %>% 
  t() %>% 
  
  
```


```{r}
imputed <- 
  df_to_impute %>% 
  arrange(year) %>% 
  drop_na(le_next_year) %>% 
  mutate(
    across(
      # no missigness in the outcome
      .cols = everything(), 
      .fns = 
         ~ifelse(
           is.na(.x),
           median(.x, na.rm = T),
           .x)
    )
  )
```

```{r}
imputed %>% 
  ggplot(
    aes(
      x = year,
      y = le_next_year
    )
  ) + 
  geom_point() + 
  geom_smooth(method = 'loess')
``` 

# Separate Data into Training and Testing

```{r}
library(rsample)
split_obj <- initial_split(imputed)
training_data <- training(split_obj)
testing_data <- training(split_obj)
```

# Fit a decision tree (without tuning hyperparameters)

Use `le_next_year` — `r outcome_descriptor`` — as your outcome.

```{r}
tree1 <- 
  rpart(
    le_next_year ~ ., 
    data = training_data,
  )
```


```{r}

```


```{r}
library(rpart.plot)
rpart.plot(tree1)
```


```{r}
library(dials)

max_entropy_grid_rf <- 
  grid_max_entropy(
    # default = floor(sqrt(ncol(training_data))) = 24
    mtry(range = c(18, 100)),
    trees(range = c(400, 1000)), 
    size = 10
  )

cp_ <- 
  function(lb = 0, ub = 1){
    dials::new_quant_param(
      type = 'double',
      range = c(lb, ub), 
      inclusive = c(TRUE, TRUE),
      label = c(cp_ = 'complexity parameter')
    )
  }

minsize_ <- 
  function(lb = 0, ub = 20){
    dials::new_quant_param(
      type = 'integer',
      range = c(lb, ub), 
      inclusive = c(TRUE, TRUE),
      label = c(minsize_ = 'minimum terminal node N')
    )
  }

max_entropy_grid_dt <- 
  grid_max_entropy(
    # default = floor(sqrt(ncol(training_data))) = 24
    cp_(),
    minsize_(), 
    size = 10
  )

```


```{r}
cv_obj <- vfold_cv(data = training_data)


cv_it_complex(
   cv_obj = cv_obj, 
    model_type = 'rf',
   mode = 'regression', 
    outcome_string = 'le_next_year',
    seed = 444, 
    mod_formula = 'le_next_year ~ .', 
    tuning_grid = max_entropy_grid, 
    verbose = TRUE,
)
```

```{r}
expand.grid(
  sp_dyn_le00_in = seq(0, 100, 5),
  year = seq(min(training_data$year), max(training_data$year), 1)
) %>% 
  mutate(
    predicted_le = predict(tree1, newdata = .)
  ) %>% 
  ggplot(
    aes(
      
      x = sp_dyn_le00_in, 
      y = predicted_le, 
      group = factor(year),
      color = factor(year)
    )
  ) +
  geom_line() +
  theme_bw()
```

# Improve the model

Use k-fold cross validation to tune the hyperparameters

```{r}
cross_validated_results <- 
  cv_it_complex(
    cv_obj = cv_obj, 
    model_type = 'dt',
    mode = 'regression', 
    outcome_string = 'le_next_year',
    seed = 444, 
    mod_formula = 'le_next_year ~ .', 
    tuning_grid = max_entropy_grid_dt, 
    verbose = TRUE
  )



plot_df <- 
  cross_validated_results %>% 
  pivot_longer(
    cols = c(rmse_mean:mae_se),
    names_to = c('metric', '.value'),
    names_sep = '_'
  ) 

plot_df %>% 
  ggplot(
    aes(
      y = fct_reorder(factor(grid_index), desc(mean)),
      x = mean, 
      fill = metric,
      group = metric, 
      xmin = mean - 1.96*se, 
      xmax = mean + 1.96*se
    )
  ) + 
  geom_col(color = 'black') + 
  geom_errorbar(width = 0.2, color = 'black') + 
  geom_label(
    aes(label = round(mean, 2)),
    color = 'black'
  ) +
  theme_bw() + 
  labs(
    caption = 
      '95% CIs drawn with t-distribution\nuse to conceptualize spread, not assess significance'
  ) +
  theme(
    plot.caption.position = 'plot',
    plot.title.position = 'plot'
    ) +
  facet_wrap(vars(metric), scales = 'free') + 
  labs(
    y = 'Grid index',
    x = 'Average Fit'
    ) 
```

```{r}
best_fit_metrics <-
  cross_validated_results %>% 
  arrange(rmse_mean, mae_mean) %>% 
  slice(1)
```


```{r}
tuned_dt <- 
  rpart(
    formula = le_next_year ~ .,
    data = training_data, 
    cp = best_fit_metrics$cp_,
    minsplit = best_fit_metrics$minsize_
  )
```

```{r}
testing_data %>%
  mutate(
    predicted_le_tuned = predict(tuned_dt, newdata = .),
    predicted_le_naive = predict(tree1, newdata = .),
  ) %>% 
  summarize(
    rmse_tuned = rmse(observed_y = le_next_year, predicted_y = predicted_le_tuned),
    mae_tuned = mae(observed_y = le_next_year, predicted_y = predicted_le_tuned),
    rmse_naive = rmse(observed_y = le_next_year, predicted_y = predicted_le_naive),
    mae_naive = mae(observed_y = le_next_year, predicted_y = predicted_le_naive),
  ) %>% 
  pivot_longer(
    cols = everything(),
   # names_to = c('.value', 'dt_type'),
    #names_sep = '_'
  ) %>% 
  separate(name, into = c('metric', 'dt_type')) %>% 
  ggplot(
    aes(
      x = dt_type,
      y = value, 
      color = metric,
    )
  ) + 
  geom_point() + 
  facet_wrap(vars(metric), scales = 'free') 
```


```{r}

expand.grid(
  sp_dyn_le00_in = seq(0, 100, 5),
  year = seq(min(training_data$year), max(training_data$year), 1)
) %>% 
  mutate(
    predicted_le = predict(tree1, newdata = .)
  ) %>% 
  ggplot(
    aes(
      
      x = sp_dyn_le00_in, 
      y = predicted_le, 
      group = factor(year),
      color = factor(year)
    )
  ) +
  geom_line() +
  theme_bw()
```


