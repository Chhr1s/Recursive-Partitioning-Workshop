---
title: "cleaning world bank data: all countries"
author: "Christopher Loan"
date: "2022-12-30"
output: html_document
---


```{r}
# data sources
# https://data.worldbank.org/topic/education?locations=TH
```

```{r}
set.seed(4444)
library(tidyverse)
library(janitor)
source(here::here('functions.R'))
dat <- 
  rio::import(
    here::here(
      'data/all_countries_wb_education_data',
      'API_4_DS2_en_csv_v2_4775247.csv'
    ),
    skip = 4,
  ) %>% 
  tibble() %>% 
  row_to_names(row_number = 1) %>% 
  clean_names() %>%
  select(
    country_name, 
    indicator_name, 
    indicator_code, 
    starts_with('x')
  )

# make a key so we have all variables easily searchable
key <- 
  dat %>% 
  select(
    indicator_name, 
    indicator_code
    ) %>% 
  mutate(
    janitor_version = janitor::make_clean_names(indicator_code)
  )
```

```{r}
library(sjmisc)
library(parallel)

cleaned <- 
  dat %>% 
  group_by(country_name) %>% 
  nest() %>% 
  mutate(
    data = 
      map(
        .x = data, 
        .f =
        ~{.x %>% 
            mutate(janitor_version = janitor::make_clean_names(indicator_code)) %>% 
            select(-indicator_name, -indicator_code) %>% 
            relocate(janitor_version, .before = everything()) %>% 
            rotate_df() %>%
            row_to_names(row_number = 1) %>%
            rownames_to_column(var = 'year') %>%
            tibble() %>%
            mutate(
              year = str_extract(string = year, regex('\\d\\d\\d\\d')),
              across(.cols = everything(), ~as.numeric(.x))
            )
        }
      ) 
  ) %>% 
  unnest(data)
```

`sl_tlf_cact_zs` = Labor force participation rate, total (% of total population ages 15+) (modeled ILO estimate)

`sl_uem_neet_zs` = Share of youth not in education, employment or training, total (% of youth population)

`se_sec_durs` = Secondary education, duration (years)

```{r}
key
```

```{r}
missingness_counter <-
  cleaned %>%
  group_by(country_name) %>%
  nest() %>%
  mutate(
    data =
      mclapply(
        mc.cores = 9L,
        X = data,
        FUN = function(x) {sum(is.na(x))}
      )
  ) %>%
  unnest(data) %>%
  ungroup()

se_asia <- 
  c(
    'Brunei Darussalam', 
    'Myanmar', 
    'Cambodia', 
    #'Timor-Leste', 
    'Indonesia', 
    'Lao PDR', 
    'Malaysia', 
    'Philippines', 
    'Singapore', 
    'Thailand',
    'Vietnam'
  )
missingness_counter %>% 
  filter(
    country_name %in% se_asia
  )
```

```{r}
library(janitor)
regional <- 
  cleaned %>% 
  filter(
    country_name %in% se_asia & year >= 2000
    ) %>% 
  remove_constant() %>% 
  remove_empty(which = 'cols') %>% 
  remove_empty(which = 'rows') 

```


```{r}
near_zero_variance <- 
  names(which(apply(regional, 2, var, na.rm = TRUE) < 0.2))

df_to_impute <-
  regional %>% 
  select(
    where(~sum(is.na(.x))/nrow(regional) < 0.25)   & -all_of(near_zero_variance)
  ) 

eligible_vars <- 
  df_to_impute %>% 
  names() 

impute_key <- 
  key %>% 
  filter(
    janitor_version %in% eligible_vars
  ) 

  
# only 7 % missing is good balance of lots of variables 
sum(is.na(df_to_impute))/(nrow(df_to_impute)*ncol(df_to_impute))
# select an outcome with no missingness

full_variables <- 
  df_to_impute %>% 
  # only retain rows with < 10% missingness:
  select(where(~sum(is.na(.x)) < 0.2*nrow(df_to_impute))) %>% 
  # no missingness:
  #select(where(~sum(is.na(.x))==0)) %>% 
  names()


df_to_impute %>% 
  select(all_of(full_variables)) %>% 
  summarize(across(.cols = everything(), .fns = var, na.rm = T)) 

outcome_key <- 
  key %>% 
  filter(
     janitor_version %in% full_variables & 
       !janitor_version %in% near_zero_variance
  )


# https://ilostat.ilo.org/resources/concepts-and-definitions/ilo-modelled-estimates/


outcome_descriptor <-
  outcome_key %>% 
  filter(janitor_version == 'se_prm_enrr') %>% 
  pull(indicator_name)

# more information at:
# https://ilostat.ilo.org/resources/concepts-and-definitions/ilo-modelled-estimates/

```


we're going to use median impute

```{r eval=FALSE, include=FALSE}
plt <-
  cleaned %>% 
  pivot_longer(
    cols = -year
  ) %>% 
  ggplot(
    aes(
      x = value, 
      color = name, 
      fill = name
    )
  ) + 
  geom_density(
    show.legend = FALSE
  ) 

plt +
  lims(x = c(0, 25))
``` 

```{r}
# differences between mean and median aren't that great (in most cases)
cleaned %>% 
  summarize(
    across(.cols = everything(),.fns = ~median(.x) - mean(.x))
  ) 
```


```{r}
imputed <- 
  df_to_impute %>% 
  group_by(country_name) %>% 
  nest() %>% 
  mutate(
    data = 
      map(
        .x = data, 
        .f = 
          ~.x %>% 
          arrange(year) %>% 
          mutate(
            ## check this
            outcome_next_year = lead(se_prm_enrr, order_by = year)
          ) %>% 
        # removes any potential issue from the `lead()` call
        # also removes prediction into covid years
          drop_na(outcome_next_year) %>% 
          mutate(
            across(
              # no missigness in the outcome
              .cols = everything(),
              .fns =
                ~ifelse(
                  is.na(.x),
                  median(.x, na.rm = T),
                  .x)
            )
      )
  )
  ) %>% 
  unnest(data) %>% 
  ungroup() %>% 
  # this keeps out covid issues and also 
  filter(year <= 2018) 
```

```{r}
#rio::export(imputed, here::here('data', 'se_asia_imputed_world_bank.csv'))
```

