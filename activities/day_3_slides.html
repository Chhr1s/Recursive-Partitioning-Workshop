<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>slides day 3</title>
    <meta charset="utf-8" />
    <meta name="author" content="Christopher M. Loan, MS" />
    <meta name="date" content="2022-02-22" />
    <script src="day_3_slides_files/header-attrs-2.16/header-attrs.js"></script>
    <link href="day_3_slides_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="day_3_slides_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <script src="day_3_slides_files/kePrint-0.0.1/kePrint.js"></script>
    <link href="day_3_slides_files/lightable-0.0.1/lightable.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# slides day 3
]
.author[
### Christopher M. Loan, MS
]
.date[
### February 22, 2022
]

---





# Workshop Progress

On Day 1, we discussed:
  * what DTs are
  * how to fit DTs
  * how to interprate/visualize DTs
  * how to evaluate DTs

On Day 2, we discussed
  
  * what RFs are
  * how to fit RFs
  * how to evaluate RFs
  * hyperparameters
  * how hyperparameters are used to improve models
  
---

# Looking Ahead

Today, we will discuss:

* Grid Search for Tuning Hyperparameters
* Cross validation
* Interpretation of Random Forests
* More Advanced Visualizations (Partial Dependency Plots)

---

# set up


```r
outcome_next_year &lt;- 'se_xpd_totl_gd_zs'
library(tidyverse)
library(ranger)
library(rsample)
library(dials)
library(kableExtra)
library(emojifont)
source(here::here('scripts/functions.R'))
```

---

# set up

Let's go ahead and get things set up like yesterday:



```r
key &lt;- 
  read.csv(here::here('data/keys', 'key_impute.csv'))

dat &lt;- 
  read.csv(
    here::here(
    'data', 
    'se_asia_imputed_world_bank.csv'
    ))


set.seed(022023)
sea_split &lt;- initial_split(dat)
sea_training &lt;- training(sea_split) 
sea_testing &lt;- testing(sea_split) 
```



Outcome =  &lt;u&gt;next year's&lt;/u&gt; Government expenditure on education, total (% of GDP)

Units = (% of GDP)

---

# let's establish two "benchmarks" to beat

## Benchmark 1: guess the average

Guessing the mean or median has common-sense validity.

The most common-sense approach is to guess the average (mean or median) se_xpd_totl_gd_zs this year to be next year's value.

If a model does not have a better RMSE than this, it is not worth using.



---

# Benchmark 2: Group-Averages


```r
group_averages &lt;- 
  sea_training %&gt;% 
  group_by(country_name) %&gt;% 
  summarize(
    predictions_group.median = median(outcome_next_year),
    predictions_group.mean = mean(outcome_next_year)
  ) %&gt;% 
  ungroup()
```


---
# Benchmark 3: Default RF


```r
rf_default &lt;- 
  ranger(
    outcome_next_year ~ ., 
    data = sea_training,
    importance = 'permutation'
  )
```

---

## A Note on RMSE

The nice thing about RMSE is that it is in the units of the outcome. 

RMSE is the average error in the units of the outcome. 

`\(RMSE = \sqrt{\frac{\Sigma (y_{actual} - y_{predicted})^2}{N}}\)`

For us, this is (% of GDP)

---

# Benchmark RMSEs


```r
benchmark_rmse &lt;- 
  sea_testing %&gt;% 
  full_join(group_averages) %&gt;% 
  transmute(
    !!sym(outcome_next_year),
    predictions_group.median,
    predictions_group.mean,
    prediction_default.rf = predict(rf_default, .)$prediction
    ) %&gt;% 
  summarize(
    rmse_guess.median = 
      rmse(observed_y = !!sym(outcome_next_year), predicted_y = naive_guess.median),
    rmse_guess.mean = 
      rmse(observed_y = !!sym(outcome_next_year), predicted_y = naive_guess.mean),
    rmse_guess.group.median = 
      rmse(observed_y = !!sym(outcome_next_year), predicted_y = predictions_group.median),
    rmse_guess.group.mean = 
      rmse(observed_y = !!sym(outcome_next_year), predicted_y = predictions_group.mean),
    rmse_default.rf = 
      rmse(observed_y = !!sym(outcome_next_year), predicted_y = prediction_default.rf)
  )
```

```
## Joining, by = "country_name"
```

---

# Benchmarks

Well, it actually looks like our group means are outperforming out default random forest. 

&lt;table&gt;
&lt;caption&gt;Fit of various benchmarks&lt;/caption&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; rmse &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; guess.median &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; guess.mean &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.52 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; guess.group.median &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.55 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; guess.group.mean &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.20 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; default.rf &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.32 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

The training mean by country better predicts the outcome than a default random forest. 

In this case, we either need to tune the model to outperform this, or else there is no reason to not take the group mean (unless you want to see VIPs, PDPs, etc)

To put this in standard "research jargon", the between-country variance is higher than within

---

# Performance of Averages

Let's actually look how bad the average guess would be for each country

![](day_3_slides_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

---


# Performance of Averages

We can get a decent estimate for a mean by group, actually.


```
## Joining, by = "country_name"
```

![](day_3_slides_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;



---

class: center, middle

# Onward &amp; Upward

Now that we've established these benchmarks, let's talk hyperparameters again

---

# Selecting Hyperparameters

Some have called tuning &amp; hyperparameter selection as much of an art as a science.

This is likely true when you're applying the basic methods we're going to cover today. 

Some automated methods are much more systematic:

* particle swarm optimization (PSO)
* genetic algorithm (GA)

Despite being more systematic:

* such methods require deeper knowledge
* most still require human decision-points
* some have their own hyper-hyperparameters!

**This is an entire field; we are only going to discuss grid search today**

---

# Grid Search

Purpose:
* (technical) Calibrate the underlying algorithms to your data
* (practical) Have the most accurate predictions 

Steps:
* make a grid of possible hyperparameters
* train models using those constraints
* estimate accuracy - MSE / classification accuracy / etc. - in predicting the outcome with unseen data for each model 

___

## Wait ... does this sound familiar?

---

# Refresher

When I demonstrated what hyperparameters are, I actually conducted 2 grid searches:
  * `num.trees`
  * `mtry`

This did not include a grid search of all possible values

---

# Let's make a grid


```r
tree_sizes &lt;- 
  seq(from = 500, to = 4000, by = 150)

mtry_values &lt;- 
  seq(from = 1, to = ncol(sea_testing)-1, 2)

all_params &lt;- 
  expand_grid(num.tree = tree_sizes, mtry = mtry_values)

dim(all_params)
```

```
## [1] 576   2
```

---

# loop through







&lt;img src="../imgs/day_3_OOB_heatmap.png" width="5232" /&gt;

---

# Predictions are pretty flat... 

As you can see, the best value isn't that much better than the worst.


On day 1, what did I say were the 3 ways to improve a model?

1. a model
2. user-specified settings (**hyperparameters**)
3. data

Because hyperparameters are evaluated on data, we actually can only find optimal settings **with respect to the training and testing data**.

By random chance, what if the training and testing sets were biased towards different settings?

This could lead to an algorithm to perform poorly, even though we conducted hyperparameter tuning.

---

# other issues with tuning via grid search

Before turning our intention to improving the data used to train, we should talk about two other issues with grid search: 

* local minimums, unless
  * you cover the **entire** space 
  * you get lucky üçÄ

* computation time increases with number of
  * hyperparameters
  * possible hyperparameter values

**Spoiler:** we're not going to cover local minimums in this workshop. Consider independent research at a later date.

---

# Increasing the variation in predictions

k-fold (a.k.a v-fold) cross-validation CV:

* improves the issues with flat predictions.
* makes of our training data to both train and test the model.
* allows variance around fit to be assessed (e.g., standard error of OOB error)
* is done **after we withhold final testing data**

The logic is a mixture of resampling and withholding for training and testing (done before):

* the data withheld here is called the "fold testing data" or "assessment data"
* the data used to train the model is called "fold training" or "analysis data"

---

# k-fold Cross Validation

Process: 
* split the training data into "k" pieces.
* train a model with a proportion of the data ($n_{train} = \frac{k-1}{k}*N_{total}$)
* assess prediction accuracy with withheld ($n_{assess} = \frac{1}{k}*N_{total}$)

For example:`n` = 1000 *observations* &amp; `k` = 10 k-fold CV
* Each fold has `n`/10 = 1000/10 = 100 observations
* Model fit for a given hyperparameter is determined

---

# Diagram


![](day_3_slides_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;



```r
library(dials)
```


```r
cv_obj &lt;- vfold_cv(sea_training, v = 10)
```


```r
max_entropy_grid &lt;-
  grid_max_entropy(
    mtry(range = c(min(mtry_values), max(mtry_values))),
    trees(range = c(min(tree_sizes), max(tree_sizes))),
    size = 150
  )
```



```r
max_entropy_grid %&gt;% 
  mutate(
    Approach = 'Maximum Entropy Grid'
  ) %&gt;% 
  bind_rows(
    all_params %&gt;% 
      mutate(Approach = 'Full Grid') %&gt;% 
      rename(trees = num.tree)
  ) %&gt;% 
  ggplot(
    aes(
      x = mtry, 
      y = trees, 
      fill = Approach,
      color = Approach,
      shape = Approach
    )
  ) +
  geom_point(size = 5, alpha = 0.5) +
  labs(
    y = 'Number of Trees',
    title = 'Coverage of Hyperparmater Space by Approach',
    subtitle = 
      'Maximum entropy grid can cover similar amount of space\nwith fewer models'
  ) +
  theme_bw(base_size = 18) +
  theme(
    legend.position = 'bottom',
    plot.title.position = 'plot'
    )
```

![](day_3_slides_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;



```r
tuned_res &lt;-
  cv_it_complex(
    cv_obj = cv_obj,
    outcome_string = 'outcome_next_year',
    seed = 333,
    mod_formula = outcome_next_year ~ .,
    tuning_grid = max_entropy_grid,
    model_type = 'rf',
    mode = 'regression'
    ) %&gt;% 
   arrange(rmse_mean)
#dir.create(here::here('data/long_runtime_objects')
write_rds(tuned_res, here::here('data/long_runtime_objects', 'day3_tuned_results.Rds'))
```


```r
tuned_res &lt;- read_rds(here::here('data/long_runtime_objects', 'day3_tuned_results.Rds'))
tuned_rf &lt;- 
  ranger(
    formula = outcome_next_year ~ ., 
    data = sea_training, 
    mtry = tuned_res$mtry[[1]],
    num.trees = tuned_res$trees[[1]],
    importance = 'permutation'
  )
```




```r
library(vip)
```

```
## 
## Attaching package: 'vip'
```

```
## The following object is masked from 'package:utils':
## 
##     vi
```

```r
vip(tuned_rf)
```

![](day_3_slides_files/figure-html/unnamed-chunk-22-1.png)&lt;!-- --&gt;





```
## Joining, by = "janitor_version"
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; order &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; indicator_name &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Government expenditure on education, total (% of GDP) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Fixed telephone subscriptions &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Industry (including construction), value added (% of GDP) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; School enrollment, preprimary (% gross) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Labor force, total &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Probability of dying among adolescents ages 10-14 years (per 1,000) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Primary education, pupils &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Primary education, teachers &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style = 'padding: 0; border:0;' colspan='100%'&gt;&lt;sup&gt;a&lt;/sup&gt; Outcome is Government expenditure on education, total (% of GDP) in the upcoming year&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;

---


```r
library(vip)
vip(tuned_rf)
```

![](day_3_slides_files/figure-html/unnamed-chunk-24-1.png)&lt;!-- --&gt;







---

# PDP: First and Second VI Scores

&lt;img src="../imgs/day_3_pdp_first_second_important_vars.png" width="3472" /&gt;

---

# PDP: First and Third VI Scores

&lt;img src="../imgs/day_3_pdp_first_third_important_vars.png" width="3472" /&gt;

---

# PDP: Second Third VI Scores

&lt;img src="../imgs/day_3_pdp_second_third_important_vars.png" width="3472" /&gt;

---

# PDP: All VI scores






&lt;img src="../imgs/day_3_pdp_top3_important_vars.png" width="4421" /&gt;


---

# PDP: By country &amp; year

We see here that our fitted RF does not actually have different predictions by country. If we had a deeper tree, or if it were more important, it would

&lt;img src="../imgs/day_3_pdp_name_year.png" width="4072" /&gt;


---

# So, what do we know about the outcome?

Well, Government expenditure on education, total (% of GDP) appears to increase along with each of the variables we investigated. 



---

# DTs, GLMs, and PDPs (oh my)




.left-column[

These models predict survival differently

refer to: 

linear vs. piecewise age effect

constant effects across passenger class vs. differential effects of (`sex` x `class` x `age`)

]

.right-column[

]
---
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
