---
title: "activity_1"
author: "Christopher Loan"
date: "2023-01-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section 0: Set seed

Set a seed at `022023`

```{r}
set.seed(022023)
```


# Section 1: Fit Decision Tree to `ptitanic` Dataset

## Section 1.1: load packages

Load 6 packages: 

1. `tidyverse`
2. `rsample`
3. `rpart`
4. `rpart.plot`
5. `vip`
6. `pdp`

```{r}
# data manipulation
library(tidyverse)
# setting up data: training / testing
library(rsample)
# decision trees
library(rpart)
# plotting decision trees
library(rpart.plot)
```

## Section 1.2: set up data

load the `ptitanic` data from the `rpart.plot` package. 

```{r}
data(ptitanic)
```

Use `relevel()` to ensure `died` is the reference group in the `ptitanic` dataset.

```{r}
ptitanic <- 
  ptitanic %>% 
  mutate(
    survived = relevel(survived, ref = 'died')
  )
```

Use `rsample` to split the data into training and testing sets.

```{r}
split_data <- initial_split(ptitanic)
training_data <- training(split_data)
testing_data <- testing(split_data)
```

## Section 1.3: Fit a Decision Tree

Predict `survived` with all other variables in the dataset

**Hint:**

There are 2 ways to include all variables:
* One is simply listing all of them, separated with `+` symbols. 
* The other is a shortcut where you list the outcome, a tilde, then a period (`.`): `outcome_name ~ .`

```{r}
all_var_DT <- 
  rpart(
    survived ~ ., 
    data = training_data
    )
```


## Section 1.4: Explore Tree Structure 

### Section 1.4.1: Look at the structure

#### Section 1.4.1a

print the tree object by just running the variable name

```{r}
all_var_DT
```

#### Section 1.4.1b

Use `rpart.plot()` to view the structure of decision the tree in a cleaner format.

```{r}
rpart.plot(
  all_var_DT,
  box.palette = 'Grays'
  )
```

#### Section 1.4.2

Use `vip()` to visualize the variable importance plot for the decision tree.

```{r}
vip(all_var_DT, geom = 'point', include_type = TRUE) + 
  theme_bw(base_size = 12) +
  labs(
    title = 'Variable Importance Plot for Decision Tree',
    subtitle = 'Data from `ptitanic`',
  )
```

#### Section 1.4.3

Use `pdp` to visualize bivariate (i.e., with 2 variables) partial dependency plots (PDPs) with pairs (i.e., 2) of the top 3 variables. Bivariate pairs of V1, V2, and V3, for example, are:
* V1 & V2
* V1 & V3
* V2 & V3

**tip:** use `plot = TRUE` in your PDP, instead of using `ggplot2`, unless you feel comfortable with `ggplot2`.

```{r}
# this is the way to use `map` to do it
# but you can just write the combinations individually

combinations <- 
  data.frame(
    combn(
      names(all_var_DT$variable.importance[1:3]), 
      m = 2)
  )


plt_list <- 
  map(
    .x = combinations,
    .f = 
      ~partial(
        all_var_DT,
        pred.var = unlist(.x),
        type = 'classification',
        which.class = 'survived',
        plot = TRUE
      )
      
  )

plt_list
```

### Section 1.5: Evaluate Model Performance (unseen data)

Use your withheld testing data to determine the percent of new predictions that are correct.

```{r}
accuracy_percentages <- 
  testing_data %>% 
  mutate(
    predicted = predict(all_var_DT, newdata = testing_data, type = 'class'), 
    actual = survived,
    prediction_accuracy = if_else(actual == predicted, 'Correct', 'Incorrect')
  ) %>% 
  count(prediction_accuracy) %>% 
  mutate(
    percent = 
      paste0(
        round(
          (n / sum(n))* 100), 
        '%'
        )
  ) 
```


When done, return your focus to the presentation
